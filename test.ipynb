{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchfunc\n",
    "import flowDatasetV2\n",
    "import flowDatasetV3\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((500,500)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((500,500)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size =10\n",
    "indices = np.arange(0, size, 1).tolist()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = flowDatasetV3.flowDataset('x',False ,0.2,data_transforms['train'])\n",
    "validation_split = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = flowDatasetV2.flowDataset(data_transforms['train'])\n",
    "validation_split = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.9295, -1.7925, -2.0323,  ..., -2.0494, -2.0494, -2.0494],\n",
      "         [-1.7754, -1.5014, -1.9809,  ..., -2.0494, -2.0494, -2.0494],\n",
      "         [-1.2103, -0.6452, -1.8439,  ..., -2.0323, -2.0323, -2.0323],\n",
      "         ...,\n",
      "         [-1.4329, -1.3473, -1.4158,  ..., -1.2617, -1.4329, -1.3815],\n",
      "         [-1.5699, -1.5528, -1.5870,  ..., -1.2959, -1.3815, -1.3644],\n",
      "         [-1.6042, -1.6213, -1.6384,  ..., -1.3644, -1.4672, -1.4672]],\n",
      "\n",
      "        [[-1.8431, -1.7031, -1.9482,  ..., -1.9657, -1.9657, -1.9657],\n",
      "         [-1.6856, -1.4055, -1.8957,  ..., -1.9657, -1.9657, -1.9657],\n",
      "         [-1.1078, -0.5301, -1.7556,  ..., -1.9482, -1.9482, -1.9482],\n",
      "         ...,\n",
      "         [-1.3354, -1.2479, -1.3179,  ..., -1.1604, -1.3354, -1.2829],\n",
      "         [-1.4755, -1.4580, -1.4930,  ..., -1.1954, -1.2829, -1.2654],\n",
      "         [-1.5105, -1.5280, -1.5455,  ..., -1.2654, -1.3704, -1.3704]],\n",
      "\n",
      "        [[-1.6127, -1.4733, -1.7173,  ..., -1.7347, -1.7347, -1.7347],\n",
      "         [-1.4559, -1.1770, -1.6650,  ..., -1.7347, -1.7347, -1.7347],\n",
      "         [-0.8807, -0.3055, -1.5256,  ..., -1.7173, -1.7173, -1.7173],\n",
      "         ...,\n",
      "         [-1.1073, -1.0201, -1.0898,  ..., -0.9330, -1.1073, -1.0550],\n",
      "         [-1.2467, -1.2293, -1.2641,  ..., -0.9678, -1.0550, -1.0376],\n",
      "         [-1.2816, -1.2990, -1.3164,  ..., -1.0376, -1.1421, -1.1421]]])\n",
      "tensor(0.2551, dtype=torch.float64)\n",
      "1307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\Flow Videos\\\\dataset\\\\frame_692.jpg', 0.2551]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3,label3 = dataset3[10]\n",
    "print(img3)\n",
    "print(label3)\n",
    "\n",
    "idx = dataset3.train_indices[10]\n",
    "print(idx)\n",
    "dataset3.train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.datapath\n",
    "b = dataset.label\n",
    "\n",
    "test = []\n",
    "train = []\n",
    "\n",
    "count = Counter(b)\n",
    "for key in count:\n",
    "    print(key)\n",
    "    indices = [i for i, x in enumerate(b) if x == key]\n",
    "    split = int(np.floor(validation_split * len(indices)))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    for i in train_indices:\n",
    "        new = [dataset.datapath[i],dataset.label[i]]\n",
    "        train.append( new)\n",
    "\n",
    "    for i in val_indices:\n",
    "        new = [dataset.datapath[i],dataset.label[i]]\n",
    "        test.append( new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = flowDatasetV2.flowDataset(False,0.2,data_transforms['train'])\n",
    "test_dataset = flowDatasetV2.flowDataset(True,0.2,data_transforms['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73dc134c273b03bbaaa405fda73e4afc8456ea2d5810584748846932e91528b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('final-year-project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
